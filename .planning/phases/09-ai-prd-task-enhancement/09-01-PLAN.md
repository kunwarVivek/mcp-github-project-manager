---
phase: 09-ai-prd-task-enhancement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/domain/ai-types.ts
  - src/domain/template-types.ts
  - src/services/ai/ConfidenceScorer.ts
  - src/services/ai/prompts/ConfidencePrompts.ts
autonomous: true

must_haves:
  truths:
    - "Confidence scores are calculated for every AI-generated section"
    - "Scores combine input quality, AI self-assessment, and pattern matching"
    - "Low confidence triggers clarifying question generation"
  artifacts:
    - path: "src/domain/ai-types.ts"
      provides: "SectionConfidence and ConfidenceConfig types"
      contains: "interface SectionConfidence"
    - path: "src/domain/template-types.ts"
      provides: "Template-related type definitions"
      contains: "interface TemplateSection"
    - path: "src/services/ai/ConfidenceScorer.ts"
      provides: "Multi-factor confidence scoring"
      exports: ["ConfidenceScorer", "calculateInputCompleteness", "calculateSectionConfidence"]
    - path: "src/services/ai/prompts/ConfidencePrompts.ts"
      provides: "Prompts for AI self-assessment"
      exports: ["CONFIDENCE_PROMPT_CONFIGS"]
  key_links:
    - from: "src/services/ai/ConfidenceScorer.ts"
      to: "src/domain/ai-types.ts"
      via: "SectionConfidence type import"
      pattern: "import.*SectionConfidence.*from"
---

<objective>
Create foundational types and confidence scoring infrastructure for AI-generated content.

Purpose: Enable per-section confidence measurement that combines input quality, AI self-assessment, and pattern matching to identify uncertain areas requiring human review or more context.

Output: Domain types for confidence scoring and templates, plus ConfidenceScorer service with multi-factor scoring logic.
</objective>

<execution_context>
@/Users/vivek/.claude/get-shit-done/workflows/execute-plan.md
@/Users/vivek/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-ai-prd-task-enhancement/09-RESEARCH.md
@src/domain/ai-types.ts
@src/services/ai/AITaskProcessor.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add confidence and template types to domain</name>
  <files>src/domain/ai-types.ts, src/domain/template-types.ts</files>
  <action>
Add new types to src/domain/ai-types.ts after the AIGenerationMetadata interface:

```typescript
/**
 * Confidence tier based on score
 */
export type ConfidenceTier = 'high' | 'medium' | 'low';

/**
 * Confidence factors that contribute to overall score
 */
export interface ConfidenceFactors {
  inputCompleteness: number;  // 0-1, based on input length, examples, constraints
  aiSelfAssessment: number;   // 0-1, from AI model's self-reported certainty
  patternMatch: number;       // 0-1, similarity to known successful patterns
}

/**
 * Per-section confidence scoring for AI-generated content
 */
export interface SectionConfidence {
  sectionId: string;
  sectionName: string;
  score: number;              // 0-100 overall confidence
  tier: ConfidenceTier;
  factors: ConfidenceFactors;
  reasoning?: string;         // AI's explanation for the score
  clarifyingQuestions?: string[];  // Generated when confidence is low
  needsReview: boolean;       // true if score < warning threshold
}

/**
 * Configuration for confidence thresholds
 */
export interface ConfidenceConfig {
  warningThreshold: number;   // Default 70 - below this shows warning
  errorThreshold: number;     // Default 50 - below this requires action
  enableIterativeRefinement: boolean;  // Auto-fetch more context when low
  maxRefinementAttempts: number;       // Default 3
}

/**
 * Default confidence configuration
 */
export const DEFAULT_CONFIDENCE_CONFIG: ConfidenceConfig = {
  warningThreshold: 70,
  errorThreshold: 50,
  enableIterativeRefinement: true,
  maxRefinementAttempts: 3
};
```

Add Zod schemas for these types after the existing AIGenerationMetadataSchema:

```typescript
export const ConfidenceTierSchema = z.enum(['high', 'medium', 'low']);

export const ConfidenceFactorsSchema = z.object({
  inputCompleteness: z.number().min(0).max(1),
  aiSelfAssessment: z.number().min(0).max(1),
  patternMatch: z.number().min(0).max(1)
});

export const SectionConfidenceSchema = z.object({
  sectionId: z.string(),
  sectionName: z.string(),
  score: z.number().min(0).max(100),
  tier: ConfidenceTierSchema,
  factors: ConfidenceFactorsSchema,
  reasoning: z.string().optional(),
  clarifyingQuestions: z.array(z.string()).optional(),
  needsReview: z.boolean()
});

export const ConfidenceConfigSchema = z.object({
  warningThreshold: z.number().min(0).max(100).default(70),
  errorThreshold: z.number().min(0).max(100).default(50),
  enableIterativeRefinement: z.boolean().default(true),
  maxRefinementAttempts: z.number().min(1).max(10).default(3)
});
```

Create new file src/domain/template-types.ts with template-related types:

```typescript
import { z } from 'zod';

/**
 * Template format detection
 */
export type TemplateFormat = 'markdown' | 'json-schema' | 'example-based';

/**
 * Template section definition
 */
export interface TemplateSection {
  id: string;
  name: string;
  description: string;
  required: boolean;
  minLength?: number;
  maxLength?: number;
  placeholder?: string;
  defaultValue?: string;
}

/**
 * Parsed template structure
 */
export interface ParsedTemplate {
  format: TemplateFormat;
  name: string;
  description?: string;
  sections: TemplateSection[];
  placeholders: string[];
  rawContent: string;
}

/**
 * Template validation result
 */
export interface TemplateValidationResult {
  valid: boolean;
  errors: string[];
  warnings: string[];
  placeholders: string[];
  missingSections: string[];
}

/**
 * Template source location
 */
export type TemplateSource =
  | { type: 'project'; path: string }
  | { type: 'org'; repo: string; path: string }
  | { type: 'url'; url: string }
  | { type: 'inline'; content: string };

/**
 * Template storage configuration
 */
export interface TemplateConfig {
  source: TemplateSource;
  name: string;
  version?: string;
  inheritsFrom?: string;  // Template ID to inherit from
}

// Zod schemas
export const TemplateFormatSchema = z.enum(['markdown', 'json-schema', 'example-based']);

export const TemplateSectionSchema = z.object({
  id: z.string(),
  name: z.string(),
  description: z.string(),
  required: z.boolean(),
  minLength: z.number().optional(),
  maxLength: z.number().optional(),
  placeholder: z.string().optional(),
  defaultValue: z.string().optional()
});

export const ParsedTemplateSchema = z.object({
  format: TemplateFormatSchema,
  name: z.string(),
  description: z.string().optional(),
  sections: z.array(TemplateSectionSchema),
  placeholders: z.array(z.string()),
  rawContent: z.string()
});

export const TemplateValidationResultSchema = z.object({
  valid: z.boolean(),
  errors: z.array(z.string()),
  warnings: z.array(z.string()),
  placeholders: z.array(z.string()),
  missingSections: z.array(z.string())
});
```
  </action>
  <verify>
Run TypeScript compilation: `npx tsc --noEmit`
Verify no compilation errors
  </verify>
  <done>
New types for SectionConfidence, ConfidenceConfig, ConfidenceFactors exist in ai-types.ts with Zod schemas.
New file template-types.ts exists with TemplateFormat, TemplateSection, ParsedTemplate types.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create confidence scoring service</name>
  <files>src/services/ai/ConfidenceScorer.ts</files>
  <action>
Create new file src/services/ai/ConfidenceScorer.ts:

```typescript
import {
  SectionConfidence,
  ConfidenceConfig,
  ConfidenceFactors,
  ConfidenceTier,
  DEFAULT_CONFIDENCE_CONFIG
} from '../../domain/ai-types';

/**
 * Calculate input completeness based on provided context
 *
 * @param input - The input data for AI generation
 * @returns Score from 0-1 representing input completeness
 */
export function calculateInputCompleteness(input: {
  description?: string;
  examples?: string[];
  constraints?: string[];
  context?: string;
  requirements?: string[];
}): number {
  let score = 0;
  let maxScore = 0;

  // Description length (up to 500 chars is optimal, max 0.3)
  maxScore += 0.3;
  if (input.description) {
    const descLen = input.description.length;
    if (descLen >= 500) {
      score += 0.3;
    } else if (descLen >= 100) {
      score += 0.2;
    } else if (descLen > 0) {
      score += 0.1;
    }
  }

  // Examples provided (max 0.2)
  maxScore += 0.2;
  if (input.examples && input.examples.length > 0) {
    score += Math.min(0.2, input.examples.length * 0.05);
  }

  // Constraints provided (max 0.2)
  maxScore += 0.2;
  if (input.constraints && input.constraints.length > 0) {
    score += Math.min(0.2, input.constraints.length * 0.04);
  }

  // Additional context (max 0.15)
  maxScore += 0.15;
  if (input.context && input.context.length > 50) {
    score += 0.15;
  } else if (input.context && input.context.length > 0) {
    score += 0.08;
  }

  // Requirements provided (max 0.15)
  maxScore += 0.15;
  if (input.requirements && input.requirements.length > 0) {
    score += Math.min(0.15, input.requirements.length * 0.03);
  }

  return Math.min(1, score / maxScore);
}

/**
 * Calculate confidence tier from score
 */
export function getConfidenceTier(score: number, config: ConfidenceConfig = DEFAULT_CONFIDENCE_CONFIG): ConfidenceTier {
  if (score >= config.warningThreshold) return 'high';
  if (score >= config.errorThreshold) return 'medium';
  return 'low';
}

/**
 * Calculate weighted confidence score from factors
 */
export function calculateWeightedScore(factors: ConfidenceFactors, weights?: {
  inputCompleteness?: number;
  aiSelfAssessment?: number;
  patternMatch?: number;
}): number {
  const w = {
    inputCompleteness: weights?.inputCompleteness ?? 0.3,
    aiSelfAssessment: weights?.aiSelfAssessment ?? 0.4,
    patternMatch: weights?.patternMatch ?? 0.3
  };

  const totalWeight = w.inputCompleteness + w.aiSelfAssessment + w.patternMatch;

  const weightedSum =
    (factors.inputCompleteness * w.inputCompleteness) +
    (factors.aiSelfAssessment * w.aiSelfAssessment) +
    (factors.patternMatch * w.patternMatch);

  return Math.round((weightedSum / totalWeight) * 100);
}

/**
 * Generate clarifying questions for low confidence areas
 */
export function generateClarifyingQuestions(
  sectionName: string,
  factors: ConfidenceFactors,
  uncertainAreas?: string[]
): string[] {
  const questions: string[] = [];

  // Questions based on low input completeness
  if (factors.inputCompleteness < 0.5) {
    questions.push(`Can you provide more details about the ${sectionName.toLowerCase()}?`);
    questions.push(`Are there specific examples or use cases for the ${sectionName.toLowerCase()} you can share?`);
  }

  // Questions based on low pattern match
  if (factors.patternMatch < 0.5) {
    questions.push(`Does the ${sectionName.toLowerCase()} follow any industry standards or existing patterns?`);
  }

  // Questions from AI's uncertain areas
  if (uncertainAreas && uncertainAreas.length > 0) {
    uncertainAreas.forEach(area => {
      questions.push(`Could you clarify: ${area}?`);
    });
  }

  return questions.slice(0, 5); // Max 5 questions
}

/**
 * Service for calculating and managing confidence scores
 */
export class ConfidenceScorer {
  private config: ConfidenceConfig;
  private patternCache: Map<string, number> = new Map();

  constructor(config: Partial<ConfidenceConfig> = {}) {
    this.config = { ...DEFAULT_CONFIDENCE_CONFIG, ...config };
  }

  /**
   * Calculate confidence for a single section
   */
  calculateSectionConfidence(params: {
    sectionId: string;
    sectionName: string;
    inputData: {
      description?: string;
      examples?: string[];
      constraints?: string[];
      context?: string;
      requirements?: string[];
    };
    aiSelfAssessment: number;  // 0-1 from AI model
    aiReasoning?: string;
    uncertainAreas?: string[];
    patternMatchScore?: number; // 0-1, optional override
  }): SectionConfidence {
    const inputCompleteness = calculateInputCompleteness(params.inputData);
    const patternMatch = params.patternMatchScore ?? this.calculatePatternMatch(params.sectionName, params.inputData);

    const factors: ConfidenceFactors = {
      inputCompleteness,
      aiSelfAssessment: params.aiSelfAssessment,
      patternMatch
    };

    const score = calculateWeightedScore(factors);
    const tier = getConfidenceTier(score, this.config);
    const needsReview = score < this.config.warningThreshold;

    const clarifyingQuestions = tier === 'low'
      ? generateClarifyingQuestions(params.sectionName, factors, params.uncertainAreas)
      : undefined;

    return {
      sectionId: params.sectionId,
      sectionName: params.sectionName,
      score,
      tier,
      factors,
      reasoning: params.aiReasoning,
      clarifyingQuestions,
      needsReview
    };
  }

  /**
   * Calculate pattern match score based on section type and content
   * Uses simple heuristics; could be enhanced with ML in future
   */
  private calculatePatternMatch(sectionName: string, inputData: {
    description?: string;
    examples?: string[];
    constraints?: string[];
  }): number {
    const cacheKey = `${sectionName}:${JSON.stringify(inputData).substring(0, 100)}`;

    if (this.patternCache.has(cacheKey)) {
      return this.patternCache.get(cacheKey)!;
    }

    let score = 0.5; // Base score

    // Check for common PRD section patterns
    const sectionLower = sectionName.toLowerCase();

    if (sectionLower.includes('overview') || sectionLower.includes('description')) {
      // Good overviews have problem statement, solution, and value prop
      if (inputData.description) {
        if (inputData.description.includes('problem') || inputData.description.includes('challenge')) score += 0.1;
        if (inputData.description.includes('solution') || inputData.description.includes('will')) score += 0.1;
        if (inputData.description.includes('value') || inputData.description.includes('benefit')) score += 0.1;
      }
    }

    if (sectionLower.includes('feature') || sectionLower.includes('requirement')) {
      // Good features have clear actions and acceptance criteria
      if (inputData.examples && inputData.examples.length > 0) score += 0.15;
      if (inputData.constraints && inputData.constraints.length > 0) score += 0.1;
    }

    if (sectionLower.includes('user') || sectionLower.includes('persona')) {
      // Good personas have goals and pain points
      if (inputData.description && inputData.description.length > 200) score += 0.2;
    }

    const finalScore = Math.min(1, score);
    this.patternCache.set(cacheKey, finalScore);
    return finalScore;
  }

  /**
   * Aggregate confidence scores from multiple sections
   */
  aggregateConfidence(sections: SectionConfidence[]): {
    overallScore: number;
    overallTier: ConfidenceTier;
    lowConfidenceSections: SectionConfidence[];
    totalSections: number;
    sectionsNeedingReview: number;
  } {
    if (sections.length === 0) {
      return {
        overallScore: 0,
        overallTier: 'low',
        lowConfidenceSections: [],
        totalSections: 0,
        sectionsNeedingReview: 0
      };
    }

    const totalScore = sections.reduce((sum, s) => sum + s.score, 0);
    const overallScore = Math.round(totalScore / sections.length);
    const overallTier = getConfidenceTier(overallScore, this.config);
    const lowConfidenceSections = sections.filter(s => s.tier === 'low');
    const sectionsNeedingReview = sections.filter(s => s.needsReview).length;

    return {
      overallScore,
      overallTier,
      lowConfidenceSections,
      totalSections: sections.length,
      sectionsNeedingReview
    };
  }

  /**
   * Get configuration
   */
  getConfig(): ConfidenceConfig {
    return { ...this.config };
  }

  /**
   * Update configuration
   */
  updateConfig(newConfig: Partial<ConfidenceConfig>): void {
    this.config = { ...this.config, ...newConfig };
  }
}
```
  </action>
  <verify>
Run TypeScript compilation: `npx tsc --noEmit`
Verify ConfidenceScorer class and all functions compile without errors
  </verify>
  <done>
ConfidenceScorer service exists with calculateInputCompleteness, calculateSectionConfidence, aggregateConfidence methods.
All helper functions (getConfidenceTier, calculateWeightedScore, generateClarifyingQuestions) are exported.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create confidence prompts for AI self-assessment</name>
  <files>src/services/ai/prompts/ConfidencePrompts.ts</files>
  <action>
Create new file src/services/ai/prompts/ConfidencePrompts.ts:

```typescript
import { z } from 'zod';

/**
 * Schema for AI self-assessment response embedded in generated content
 */
export const AIConfidenceAssessmentSchema = z.object({
  score: z.number().min(0).max(100).describe('Overall confidence score 0-100'),
  reasoning: z.string().describe('Brief explanation of confidence level'),
  uncertainAreas: z.array(z.string()).describe('Specific areas of uncertainty'),
  clarifyingQuestions: z.array(z.string()).optional().describe('Questions that would increase confidence')
});

export type AIConfidenceAssessment = z.infer<typeof AIConfidenceAssessmentSchema>;

/**
 * Prompt configuration for confidence-aware generation
 */
export interface ConfidencePromptConfig {
  systemPrompt: string;
  userPromptTemplate: string;
  temperature: number;
  maxTokens: number;
}

/**
 * Format confidence prompt with variables
 */
export function formatConfidencePrompt(template: string, variables: Record<string, string>): string {
  let result = template;
  for (const [key, value] of Object.entries(variables)) {
    result = result.replace(new RegExp(`\\{${key}\\}`, 'g'), value);
  }
  return result;
}

/**
 * Confidence prompt configurations for different content types
 */
export const CONFIDENCE_PROMPT_CONFIGS = {
  /**
   * Self-assessment prompt suffix to append to any generation request
   */
  selfAssessmentSuffix: `

After generating the content, also provide a confidence assessment:
1. Rate your confidence (0-100) in the generated content
2. Explain your confidence level briefly
3. List any areas where you're uncertain
4. Suggest questions that would help improve the output

Be honest about uncertainty. High confidence should only be claimed when:
- The input provides sufficient detail
- The request is clear and unambiguous
- The output follows established patterns
- No significant assumptions were required`,

  /**
   * PRD section confidence assessment
   */
  prdSectionAssessment: {
    systemPrompt: `You are an expert PRD reviewer. Your task is to assess the quality and completeness of PRD sections.

Evaluate each section based on:
1. Completeness - Does it cover all necessary information?
2. Clarity - Is the content clear and unambiguous?
3. Actionability - Can someone execute on this content?
4. Consistency - Does it align with other PRD sections?

Be calibrated in your confidence. Common issues that should lower confidence:
- Vague or generic descriptions
- Missing acceptance criteria
- Unclear user personas
- Ambiguous technical requirements
- Missing success metrics`,
    userPromptTemplate: `Assess the following PRD section:

Section: {sectionName}
Content:
{content}

Context from other sections:
{context}

Provide your assessment as JSON matching this schema:
- score: 0-100 confidence in the section quality
- reasoning: Brief explanation
- uncertainAreas: List of unclear/incomplete areas
- clarifyingQuestions: Questions to improve the section`,
    temperature: 0.3,
    maxTokens: 500
  },

  /**
   * Task confidence assessment
   */
  taskAssessment: {
    systemPrompt: `You are an expert at evaluating task definitions and estimates.

Evaluate tasks based on:
1. Clarity of requirements
2. Completeness of acceptance criteria
3. Accuracy of complexity/effort estimates
4. Correctness of dependency identification
5. Feasibility given the context

Be honest about uncertainty in estimates. Task estimation inherently has variance.`,
    userPromptTemplate: `Assess the following task:

Title: {title}
Description: {description}
Estimated Complexity: {complexity}
Estimated Effort: {effort}
Dependencies: {dependencies}
Acceptance Criteria: {acceptanceCriteria}

PRD Context:
{prdContext}

Provide your assessment as JSON:
- score: 0-100 confidence in task definition quality
- reasoning: Brief explanation
- uncertainAreas: Areas needing clarification
- clarifyingQuestions: Questions that would improve the task`,
    temperature: 0.3,
    maxTokens: 500
  },

  /**
   * Dependency detection confidence
   */
  dependencyAssessment: {
    systemPrompt: `You are an expert at analyzing task dependencies in software projects.

Look for:
1. Technical dependencies (API needs DB, UI needs API)
2. Data dependencies (Task B needs output from Task A)
3. Logical dependencies (Testing after implementation)
4. Resource dependencies (Shared infrastructure)

Be conservative - only flag dependencies you're confident about.
Mark uncertain dependencies for human review.`,
    userPromptTemplate: `Analyze dependencies for these tasks:

Tasks:
{taskList}

For each detected dependency, rate your confidence (0-100) and explain why.

Format as JSON array with:
- fromTaskId: Task that depends on another
- toTaskId: Task being depended upon
- type: 'blocks' | 'depends_on' | 'related_to'
- confidence: 0-100
- reasoning: Why this dependency exists`,
    temperature: 0.2,
    maxTokens: 1000
  },

  /**
   * Effort estimation confidence
   */
  effortAssessment: {
    systemPrompt: `You are an expert at estimating software development effort.

Consider:
1. Task complexity (logic, algorithms, edge cases)
2. Integration points (APIs, databases, services)
3. Testing requirements
4. Documentation needs
5. Similar tasks from experience

Express uncertainty through confidence scores. Simple CRUD = high confidence.
Novel algorithms or complex integrations = lower confidence.

Use story points (Fibonacci: 1, 2, 3, 5, 8, 13) by default.`,
    userPromptTemplate: `Estimate effort for:

Task: {title}
Description: {description}
Technical Context: {technicalContext}
Similar Completed Tasks: {historicalData}

Provide:
- estimate: number (story points)
- confidence: 0-100
- reasoning: Brief explanation
- range: {low: number, high: number} representing uncertainty
- risks: Factors that could affect the estimate`,
    temperature: 0.3,
    maxTokens: 400
  }
};

/**
 * Create a schema that includes confidence assessment
 */
export function withConfidenceAssessment<T extends z.ZodRawShape>(
  contentSchema: z.ZodObject<T>
): z.ZodObject<T & { confidenceAssessment: typeof AIConfidenceAssessmentSchema }> {
  return contentSchema.extend({
    confidenceAssessment: AIConfidenceAssessmentSchema
  });
}
```
  </action>
  <verify>
Run TypeScript compilation: `npx tsc --noEmit`
Verify all exports and schema types compile correctly
  </verify>
  <done>
ConfidencePrompts.ts exists with CONFIDENCE_PROMPT_CONFIGS for PRD, task, dependency, and effort assessment.
AIConfidenceAssessmentSchema defines the structure for AI self-assessment.
withConfidenceAssessment helper extends any Zod schema with confidence fields.
  </done>
</task>

</tasks>

<verification>
1. Run `npx tsc --noEmit` - no TypeScript errors
2. Verify src/domain/ai-types.ts exports SectionConfidence, ConfidenceConfig, ConfidenceFactors
3. Verify src/domain/template-types.ts exists with TemplateFormat, TemplateSection, ParsedTemplate
4. Verify src/services/ai/ConfidenceScorer.ts exports ConfidenceScorer class and helper functions
5. Verify src/services/ai/prompts/ConfidencePrompts.ts exports CONFIDENCE_PROMPT_CONFIGS
</verification>

<success_criteria>
- All TypeScript files compile without errors
- SectionConfidence interface captures per-section confidence with factors
- ConfidenceScorer.calculateSectionConfidence returns proper SectionConfidence object
- calculateInputCompleteness correctly weights description, examples, constraints
- CONFIDENCE_PROMPT_CONFIGS has entries for PRD, task, dependency, effort assessment
- Template types ready for Plan 02 template engine implementation
</success_criteria>

<output>
After completion, create `.planning/phases/09-ai-prd-task-enhancement/09-01-SUMMARY.md`
</output>
